{"cells":[{"cell_type":"code","source":["\ndbutils.widgets.text(\"Path (for new batch data)\", '/mnt/dacoursedatabricksstg/dacoursedatabricksdata/busFile')\ndbutils.widgets.text(\"IP (for new stream data)\", '10.0.0.30')\n\nbatch_path = dbutils.widgets.get(\"Path (for new batch data)\")\nstream_ip = dbutils.widgets.get(\"IP (for new stream data)\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19c73b0b-7649-460d-bfc5-d5c296168aaa"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{"Path (for new batch data)":{"name":"Path (for new batch data)","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"/mnt/dacoursedatabricksstg/dacoursedatabricksdata/busFile"},"IP (for new stream data)":{"name":"IP (for new stream data)","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"10.0.0.30"}},"type":"html","arguments":{"Path (for new batch data)":"/mnt/dacoursedatabricksstg/dacoursedatabricksdata/busFile","IP (for new stream data)":"10.0.0.30"}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pyspark.sql.functions as F\nfrom pyspark.ml import Pipeline\nfrom pyspark.sql.types import *\nfrom pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoderEstimator, Imputer\nfrom pyspark.ml.classification import RandomForestClassifier, LogisticRegression\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.mllib.classification import StreamingLogisticRegressionWithSGD\nimport pandas as pd\nimport datetime\nfrom sklearn.metrics import mean_squared_error, accuracy_score\n\nip = '10.0.0.4'\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c71ea99d-cbff-41fb-9a3b-74641f63fb17"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import *\n\nschema = StructType([StructField('_id',StructType([StructField('$oid',StringType(),True)]),True),\n                     StructField('actualDelay',DoubleType(),True),\n                     StructField('angle',DoubleType(),True),\n                     StructField('anomaly',BooleanType(),True),\n                     StructField('areaId',LongType(),True),\n                     StructField('areaId1',LongType(),True),\n                     StructField('areaId2',LongType(),True),\n                     StructField('areaId3',LongType(),True),\n                     StructField('atStop',BooleanType(),True),\n                     StructField('busStop',LongType(),True),\n                     StructField('calendar',StructType([StructField('$numberLong',StringType(),True)]),True),\n                     StructField('congestion',BooleanType(),True),\n                     StructField('currentHour',LongType(),True),\n                     StructField('dateType',LongType(),True),\n                     StructField('dateTypeEnum',StringType(),True),\n                     StructField('delay',LongType(),True),\n                     StructField('direction',LongType(),True),\n                     StructField('distanceCovered',DoubleType(),True),\n                     StructField('ellapsedTime',LongType(),True),\n                     StructField('filteredActualDelay',LongType(),True),\n                     StructField('gridID',StringType(),True),\n                     StructField('journeyPatternId',StringType(),True),\n                     StructField('justLeftStop',BooleanType(),True),\n                     StructField('justStopped',BooleanType(),True),\n                     StructField('latitude',DoubleType(),True),\n                     StructField('lineId',StringType(),True),\n                     StructField('loc',StructType([StructField('coordinates',ArrayType(DoubleType(),True),True),\n                                                   StructField('type',StringType(),True)]),True),\n                     StructField('longitude',DoubleType(),True),\n                     StructField('poiId',LongType(),True),\n                     StructField('poiId2',LongType(),True),\n                     StructField('probability',DoubleType(),True),\n                     StructField('systemTimestamp',DoubleType(),True),\n                     StructField('timestamp',StructType([StructField('$numberLong',StringType(),True)]),True),\n                     StructField('vehicleId',LongType(),True),\n                     StructField('vehicleSpeed',DoubleType(),True)])"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e1248589-979e-4bd5-97e4-eee562480486"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["import pyspark.sql.functions as F\nfrom pyspark.sql.types import *\nfrom elasticsearch import Elasticsearch\nimport pandas as pd\n\n# read data file\ndef read_data(data):\n  if data == 'full':\n    df = spark.read.json('/mnt/dacoursedatabricksstg/dacoursedatabricksdata/busFile', schema=schema)        \n  elif data == 'small':\n    df = spark.read.json('/FileStore/tables/mini_sample.json', schema=schema)\n  elif data == 'first':    \n    df = spark.read.json('/FileStore/tables/seq_sample.json', schema=schema)\n  else:\n    raise('error')\n  print('finished read_data')\n  return df\n\n\n# a class of an event\nclass Public_Event:\n    def __init__(self, row):\n        self.parse_date(row)\n        place_dict = {'aviva': [980, 3910, 3912, 3913, 3914, 3915, 3916, 3883, 3884, 3886, 3888, 3889, 3890, 3891, 3892, 4565, 4567, 4573, 4574, 4575, 4576, 1149, 1151], 'croke': [4581, 4583, 4589, 4591, 4480, 4483, 4484, 4566, 4568, 4577, 4569, 4574, 4579, 4572, 4580, 4578, 4571, 4570, 4576]}\n        self.areaIds = place_dict[row['stadium']]\n        self.event = row['event']\n        \n    # get starting and finishing times of the event\n    def parse_date(self, row):\n        year = int(row['year'])\n        month = int(row['month'])\n        day = int(row['day'])\n        start_finish_hour = int(row['start_finish_hour'])\n        start_finish_minute = int(row['start_finish_minute'])\n\n        self.start_finish = datetime.datetime(year, month, day, start_finish_hour, start_finish_minute)\n\n        if row['event'] == 'concert':\n            start_begin_hour = int(row['start_begin_hour'])\n            start_begin_minute = int(row['start_begin_minute'])\n            self.start_begin = datetime.datetime(year, month, day, start_begin_hour, start_begin_minute)\n        else:\n            self.start_begin = self.start_finish - datetime.timedelta(hours=1, minutes=0)\n            self.end_begin = self.start_finish + datetime.timedelta(hours=1, minutes=50)\n            self.end_finish = self.start_finish + datetime.timedelta(hours=2, minutes=15)\n\n    \n    # return for a datetime and areaid3 if its close to an event\n    def is_close(self, year, month, day, hour, minute, areaId3):\n        date = datetime.datetime(year, month, day, hour, minute)\n        if self.event == 'concert' and (areaId3 in self.areaIds and \n           self.start_begin <= date <= self.start_finish):\n            print('concert')\n            return self.event\n        elif self.event != 'concert' and (areaId3 in self.areaIds and \n           (self.start_begin <= date <= self.start_finish or self.end_begin <= date <= self.end_finish)):\n            print('other')\n            return self.event\n        else:\n            print('no', end=', ')\n            return 'no'\n\n# parse all the events       \ndef parse_events():\n    df_events = pd.read_csv(\"/dbfs/FileStore/shared_uploads/moshe.abadi@campus.technion.ac.il/events-1.csv\")\n#     display(df_events)\n    events_list = []\n    for i, row in df_events.iterrows():\n        events_list.append(Public_Event(row))\n    return events_list\nevents_list = parse_events()\n# tag every report from the bus if and which event is close\n@F.udf()\ndef tag_reports(minute, hour, day, month, year, areaId):\n    for event in events_list:\n        event_close = event.is_close(year, month, day, hour, minute, areaId)\n        if event_close != 'no':\n            return event_close\n    return 'no'\n\nclass Tweet:\n    def __init__(self, row):\n        self.parse_date(row)\n        self.tweet = row\n        \n    # get starting and finishing times of the tweet\n    def parse_date(self, row):\n        year = int(row['year'])\n        month = int(row['month'])\n        day = int(row['day'])\n        hour = int(row['hour'])\n        minute = int(row['minute'])\n\n        self.tweetime = datetime.datetime(year, month, day, hour, minute)\n\n        self.start = self.tweetime - datetime.timedelta(hours=1, minutes=0)\n        self.finish = self.tweetime + datetime.timedelta(hours=1, minutes=0)\n\n    \n    # return for a datetime and areaid3 if its close to an tweet\n    def is_close(self, year, month, day, hour, minute):\n        date = datetime.datetime(year, month, day, hour, minute)\n        if self.start <= date <= self.finish:\n            return self.tweet['text']\n        else:\n            return 'no'\n\n# parse all the events       \ndef parse_tweets():\n    df_tweets = pd.read_csv(\"/dbfs/FileStore/shared_uploads/moshe.abadi@campus.technion.ac.il/combined_csv.csv\")\n    tweets_list = []\n    for i, row in df_tweets.iterrows():\n        tweets_list.append(Tweet(row))\n    return tweets_list\ntweets_list = parse_tweets()\n\n# tag every report from the bus if and which tweet is close\n@F.udf()\ndef tag_tweets(minute, hour, day, month, year):\n    for tweet in tweets_list:\n        tweet_close = tweet.is_close(year, month, day, hour, minute)\n        if tweet_close != 'no':\n            return tweet_close\n    return 'no'\n\n\n@F.udf()\ndef prefix(s):\n  return s[:4]\n@F.udf()\ndef direction(s):\n  return s[4]\n@F.udf()\ndef loc(lat, lon):\n  return ','.join([lat, lon])\n@F.udf('int')\ndef delay_interval(delay):\n    if delay <= -600:\n        return 0\n    elif -600 < delay <= -300:\n        return 1\n    elif -300 < delay <= -180:\n        return 2\n    elif -180 < delay <= -60:\n        return 3\n    elif -60 < delay <= 60:\n        return 4\n    elif 60 < delay <= 180:\n        return 5\n    elif 180 < delay <= 300:\n        return 6\n    elif 300 < delay <= 600:\n        return 7\n    elif 600 < delay:\n        return 8\n\n# parse and remove uneeded columns\ndef pre_process(df):\n  df = df.withColumn('id', F.col('_id.$oid'))\n  df = df.withColumn('patternLine', prefix(F.col(\"journeyPatternId\")))\n  df = df.withColumn('directionLine', direction(F.col(\"journeyPatternId\")))\n  df = df.withColumn('delay_interval', delay_interval(F.col(\"delay\")))\n  df = df.withColumn(\"actualDelay\", df[\"actualDelay\"].cast(\"double\"))\n  df = df.withColumn('coordinates', df['loc']['coordinates'])\n  df = df.withColumn('timestamp', F.col('timestamp.$numberLong'))\n  spark.conf.set(\"spark.sql.session.timeZone\", \"Europe/Dublin\")\n  df = df.withColumn('datetime', F.from_unixtime(F.substring(F.col(\"timestamp\"),0,10))) #.cast(DateType())\n  df = df.withColumn('dayOfWeek', F.dayofweek(df['datetime']))\n  df = df.withColumn('minute', F.minute(df['datetime']))\n  df = df.withColumn('hour', F.hour(df['datetime']))\n  df = df.withColumn('day', F.dayofmonth(df['datetime']))\n  df = df.withColumn('month', F.month(df['datetime']))\n  df = df.withColumn('year', F.year(df['datetime']))\n  df = df.withColumn(\"event_around\", tag_reports(F.col(\"minute\"), F.col(\"hour\"), F.col(\"day\"), F.col(\"month\"), F.col(\"year\"), F.col(\"areaId3\")))\n  df = df.withColumn(\"relevant_tweet\", tag_tweets(F.col(\"minute\"), F.col(\"hour\"), F.col(\"day\"), F.col(\"month\"), F.col(\"year\")))\n  df = df.withColumn(\"event_around_bool\", F.when(F.col(\"event_around\") != \"no\", False).otherwise(False))\n  df = df.withColumn(\"relevant_tweet_bool\", F.when(F.col(\"relevant_tweet\") != \"no\", False).otherwise(False))\n  \n\n  df = df.drop(*['_id', 'angle', 'anomaly', 'direction', 'dateType', 'dateTypeEnum', 'poiId', 'poiId2', 'probability', 'filteredActualDelay', 'calendar', 'loc', 'systemTimestamp', 'currentHour', 'timestamp'])\n  print('finished pre_process')\n  return df\n\n# remove ouliers from selected columns\ndef remove_outliers(df):\n  outliers_ranges = {'vehicleSpeed': [0, 120], 'actualDelay': [-2200, 2000], 'delay': [-10000, 10000], 'distanceCovered': [0, 5]}\n  \n  outliers_cols = ['actualDelay', 'delay', 'distanceCovered', 'vehicleSpeed',]\n  for outlier_col, outlier_range in outliers_ranges.items():\n    mini = outlier_range[0]\n    maxi = outlier_range[1]\n\n    \n    df = df.withColumn(outlier_col, F.when((df[outlier_col] >= mini) & (df[outlier_col] <= maxi), df[outlier_col]))\n#     df = col_remove_outliers(df, outlier_col)\n  print('finished remove_outliers')\n  return df\n\n\nip = '10.0.0.4'\n# ip = 'da2020w-0000.eastus.cloudapp.azure.com'\n\n# upload the data to elastic\ndef upload(df, data):\n  index = 'df_'+data\n  es = Elasticsearch([{'host': ip}], request_timeout=30000)\n  if es.indices.exists(index):\n      es.indices.delete(index=index)\n\n  DEFUALT_SCEHMA = {\n    \"settings\": {\n        \"number_of_shards\": 1,\n        \"number_of_replicas\": 0\n    },\n    \"mappings\": {\n        \"properties\": {\n            \"actualDelay\" : { \"type\": \"double\" },\n            \"areaId\" : { \"type\": \"long\" },\n            \"areaId1\" : { \"type\": \"long\" },\n            \"areaId2\" : { \"type\": \"long\" },\n            \"areaId3\" : { \"type\": \"long\" },\n            \"atStop\" : { \"type\": \"boolean\" },\n            \"busStop\" : { \"type\": \"long\" },\n            \"congestion\" : { \"type\": \"boolean\" },\n            \"coordinates\" : { \"type\": \"geo_point\" },\n            \"datetime\" : { \"type\": \"date\", \"format\": \"yyyy-MM-dd HH:mm:ss\"},#2017-07-24 09:13:47\n            \"dayOfWeek\" : { \"type\": \"long\" },\n            \"delay\" : { \"type\": \"long\" },\n            \"distanceCovered\" : { \"type\": \"double\" },\n            \"ellapsedTime\" : { \"type\": \"double\" },\n            \"hour\" : { \"type\": \"long\" },\n            \"gridID\" : { \"type\": \"keyword\" },\n            \"id\" : { \"type\": \"keyword\" },\n            \"journeyPatternId\" : { \"type\": \"keyword\" },\n            \"justLeftStop\" : { \"type\": \"boolean\" },\n            \"justStopped\" : { \"type\": \"boolean\" },\n            \"latitude\" : { \"type\": \"double\" },\n            \"lineId\" : { \"type\": \"keyword\" },\n            \"longitude\" : { \"type\": \"double\" },\n            \"minute\" : { \"type\": \"long\" },\n            \"vehicleId\" : { \"type\": \"long\" },\n            \"vehicleSpeed\" : { \"type\": \"long\" },\n            \"patternLine\" : { \"type\": \"keyword\" },\n        }\n    }\n}  \n\n  es.indices.create(index=index, ignore=400, request_timeout=30000, body=DEFUALT_SCEHMA)\n  df.write.format(\"org.elasticsearch.spark.sql\")\\\n          .option(\"es.nodes\",ip)\\\n          .option(\"es.resource\", index)\\\n          .option(\"es.nodes.wan.only\",\"true\")\\\n          .save()\n    \n  print('finished upload')\n  \n# download data from elastic\ndef elastic_import(index):\n  q = \"\"\"\n  {\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"range\": {\n            \"datetime\": {\n              \"gte\": \"2017-05-26T07:40:30.795Z\",\n              \"lte\": \"2018-10-06T03:08:25.541Z\",\n              \"format\": \"strict_date_optional_time\"\n            }\n          }\n        }\n      ]\n    }\n  }\n  }\"\"\"\n  \n  return spark.read.format(\"org.elasticsearch.spark.sql\")\\\n                 .option(\"es.nodes.wan.only\", \"true\")\\\n                 .option(\"es.mapping.date.rich\", \"false\")\\\n                 .option(\"es.port\", \"9200\")\\\n                 .option(\"es.nodes\", ip)\\\n                 .option(\"pushdown\", \"true\")\\\n                 .load(index)\n#                  .option(\"es.query\", q)\\\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"52fb4ab2-1948-484b-a8f9-1a48925e684d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# data = 'small'\n# # data = 'first'\ndata = 'full'\nprint('data =', data)\n\ndf = read_data(data=data)\ndf = pre_process(df)\ndf = remove_outliers(df)\n# display(df)\nupload(df, data)\n\n# df = elastic_import('df_'+data)\n# df = df.withColumn(\"actualDelay\", df[\"actualDelay\"].cast(DoubleType()))\n# df = df.withColumn(\"vehicleSpeed\", df[\"vehicleSpeed\"].cast(DoubleType()))\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4c0791a5-3b87-40b7-aa3d-77707f9a40f0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"actualDelay","nullable":true,"type":"double"},{"metadata":{},"name":"areaId","nullable":true,"type":"long"},{"metadata":{},"name":"areaId1","nullable":true,"type":"long"},{"metadata":{},"name":"areaId2","nullable":true,"type":"long"},{"metadata":{},"name":"areaId3","nullable":true,"type":"long"},{"metadata":{},"name":"atStop","nullable":true,"type":"boolean"},{"metadata":{},"name":"busStop","nullable":true,"type":"long"},{"metadata":{},"name":"congestion","nullable":true,"type":"boolean"},{"metadata":{},"name":"delay","nullable":true,"type":"long"},{"metadata":{},"name":"distanceCovered","nullable":true,"type":"double"},{"metadata":{},"name":"ellapsedTime","nullable":true,"type":"long"},{"metadata":{},"name":"gridID","nullable":true,"type":"string"},{"metadata":{},"name":"journeyPatternId","nullable":true,"type":"string"},{"metadata":{},"name":"justLeftStop","nullable":true,"type":"boolean"},{"metadata":{},"name":"justStopped","nullable":true,"type":"boolean"},{"metadata":{},"name":"latitude","nullable":true,"type":"double"},{"metadata":{},"name":"lineId","nullable":true,"type":"string"},{"metadata":{},"name":"longitude","nullable":true,"type":"double"},{"metadata":{},"name":"vehicleId","nullable":true,"type":"long"},{"metadata":{},"name":"vehicleSpeed","nullable":true,"type":"double"},{"metadata":{},"name":"id","nullable":true,"type":"string"},{"metadata":{},"name":"patternLine","nullable":true,"type":"string"},{"metadata":{},"name":"directionLine","nullable":true,"type":"string"},{"metadata":{},"name":"delay_interval","nullable":true,"type":"integer"},{"metadata":{},"name":"coordinates","nullable":true,"type":{"containsNull":true,"elementType":"double","type":"array"}},{"metadata":{},"name":"datetime","nullable":true,"type":"string"},{"metadata":{},"name":"dayOfWeek","nullable":true,"type":"integer"},{"metadata":{},"name":"minute","nullable":true,"type":"integer"},{"metadata":{},"name":"hour","nullable":true,"type":"integer"},{"metadata":{},"name":"day","nullable":true,"type":"integer"},{"metadata":{},"name":"month","nullable":true,"type":"integer"},{"metadata":{},"name":"year","nullable":true,"type":"integer"},{"metadata":{},"name":"event_around","nullable":true,"type":"string"},{"metadata":{},"name":"relevant_tweet","nullable":true,"type":"string"},{"metadata":{},"name":"event_around_bool","nullable":false,"type":"boolean"},{"metadata":{},"name":"relevant_tweet_bool","nullable":false,"type":"boolean"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">data = small\nfinished read_data\nfinished pre_process\nfinished remove_outliers\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">data = small\nfinished read_data\nfinished pre_process\nfinished remove_outliers\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["imputer_cols = ['actualDelay'] #'distanceCovered', 'vehicleSpeed']\nstr_to_ix_col = ['patternLine'] #, 'event_around']\nohe_cols = ['hour', 'busStop', 'dayOfWeek']\n#  'areaId',\ncont_cols = ['atStop',]# 'justLeftStop', 'justStopped', 'ellapsedTime', 'congestion']\n\npred_col = 'delay_interval'\n\n\nimputer = Imputer(\n        missingValue=float('nan'),\n        inputCols=imputer_cols,\n        outputCols=[col + '_mean' for col in imputer_cols],\n)\n\nstr_to_ix1 = StringIndexer(\n    inputCol=str_to_ix_col[0],\n    outputCol=str_to_ix_col[0] + '_ix',\n)\n\n# str_to_ix2 = StringIndexer(\n#     inputCol=str_to_ix_col[0],\n#     outputCol=str_to_ix_col[0] + '_ix',\n# )\n\nohe = OneHotEncoderEstimator(\n        inputCols=ohe_cols + [str_to_ix1.getOutputCol()] ,#+ [str_to_ix2.getOutputCol()],\n        outputCols=[col + '_ohe' for col in ohe_cols] + [col + '_ohe' for col in [str_to_ix1.getOutputCol()]],#+[str_to_ix2.getOutputCol()]],\n)\n\nvec_assembler = VectorAssembler(\n        inputCols=cont_cols + ohe.getOutputCols() + imputer.getOutputCols(),\n        outputCol='features',\n)\n\nrf = RandomForestClassifier(\n        featuresCol='features',\n        labelCol=pred_col,\n        predictionCol=pred_col+'_pred',\n        rawPredictionCol=pred_col+'_rawpred',\n        maxDepth=5, \n        maxBins=32, \n        minInstancesPerNode=1\n)\n\nlr = LogisticRegression(\n        featuresCol='features',\n        labelCol=pred_col,\n        predictionCol=pred_col+'_pred',\n        rawPredictionCol=pred_col+'_rawpred',\n)\n\n\nevaluator = MulticlassClassificationEvaluator(predictionCol='delay_interval_pred', labelCol='delay_interval', metricName='f1')\n# f1|weightedPrecision|weightedRecall|accuracy"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f345799-203a-4f28-b000-a593444214bb"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["df_train, df_test = df.randomSplit([0.9, 0.1], seed=0)\n\npipeline = Pipeline(stages=[\n    imputer,\n    str_to_ix1,\n#     str_to_ix2,\n    ohe,\n    vec_assembler,\n    lr,\n])\n\nprint('train len =', df_train.count())\npipeline_model = pipeline.fit(df_train)\n\n# print('test len =', df_test.count())\n# preds = pipeline_model.transform(df_test)\n# score = evaluator.evaluate(preds)\n# print(score)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c715ab79-fcd4-40ae-816a-c8507ea2331b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df_train","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"actualDelay","nullable":true,"type":"double"},{"metadata":{},"name":"areaId","nullable":true,"type":"long"},{"metadata":{},"name":"areaId1","nullable":true,"type":"long"},{"metadata":{},"name":"areaId2","nullable":true,"type":"long"},{"metadata":{},"name":"areaId3","nullable":true,"type":"long"},{"metadata":{},"name":"atStop","nullable":true,"type":"boolean"},{"metadata":{},"name":"busStop","nullable":true,"type":"long"},{"metadata":{},"name":"congestion","nullable":true,"type":"boolean"},{"metadata":{},"name":"delay","nullable":true,"type":"long"},{"metadata":{},"name":"distanceCovered","nullable":true,"type":"double"},{"metadata":{},"name":"ellapsedTime","nullable":true,"type":"long"},{"metadata":{},"name":"gridID","nullable":true,"type":"string"},{"metadata":{},"name":"journeyPatternId","nullable":true,"type":"string"},{"metadata":{},"name":"justLeftStop","nullable":true,"type":"boolean"},{"metadata":{},"name":"justStopped","nullable":true,"type":"boolean"},{"metadata":{},"name":"latitude","nullable":true,"type":"double"},{"metadata":{},"name":"lineId","nullable":true,"type":"string"},{"metadata":{},"name":"longitude","nullable":true,"type":"double"},{"metadata":{},"name":"vehicleId","nullable":true,"type":"long"},{"metadata":{},"name":"vehicleSpeed","nullable":true,"type":"double"},{"metadata":{},"name":"id","nullable":true,"type":"string"},{"metadata":{},"name":"patternLine","nullable":true,"type":"string"},{"metadata":{},"name":"directionLine","nullable":true,"type":"string"},{"metadata":{},"name":"delay_interval","nullable":true,"type":"integer"},{"metadata":{},"name":"coordinates","nullable":true,"type":{"containsNull":true,"elementType":"double","type":"array"}},{"metadata":{},"name":"datetime","nullable":true,"type":"string"},{"metadata":{},"name":"dayOfWeek","nullable":true,"type":"integer"},{"metadata":{},"name":"minute","nullable":true,"type":"integer"},{"metadata":{},"name":"hour","nullable":true,"type":"integer"},{"metadata":{},"name":"day","nullable":true,"type":"integer"},{"metadata":{},"name":"month","nullable":true,"type":"integer"},{"metadata":{},"name":"year","nullable":true,"type":"integer"},{"metadata":{},"name":"event_around","nullable":true,"type":"string"},{"metadata":{},"name":"relevant_tweet","nullable":true,"type":"string"},{"metadata":{},"name":"event_around_bool","nullable":false,"type":"boolean"},{"metadata":{},"name":"relevant_tweet_bool","nullable":false,"type":"boolean"}],"type":"struct"},"tableIdentifier":null},{"name":"df_test","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"actualDelay","nullable":true,"type":"double"},{"metadata":{},"name":"areaId","nullable":true,"type":"long"},{"metadata":{},"name":"areaId1","nullable":true,"type":"long"},{"metadata":{},"name":"areaId2","nullable":true,"type":"long"},{"metadata":{},"name":"areaId3","nullable":true,"type":"long"},{"metadata":{},"name":"atStop","nullable":true,"type":"boolean"},{"metadata":{},"name":"busStop","nullable":true,"type":"long"},{"metadata":{},"name":"congestion","nullable":true,"type":"boolean"},{"metadata":{},"name":"delay","nullable":true,"type":"long"},{"metadata":{},"name":"distanceCovered","nullable":true,"type":"double"},{"metadata":{},"name":"ellapsedTime","nullable":true,"type":"long"},{"metadata":{},"name":"gridID","nullable":true,"type":"string"},{"metadata":{},"name":"journeyPatternId","nullable":true,"type":"string"},{"metadata":{},"name":"justLeftStop","nullable":true,"type":"boolean"},{"metadata":{},"name":"justStopped","nullable":true,"type":"boolean"},{"metadata":{},"name":"latitude","nullable":true,"type":"double"},{"metadata":{},"name":"lineId","nullable":true,"type":"string"},{"metadata":{},"name":"longitude","nullable":true,"type":"double"},{"metadata":{},"name":"vehicleId","nullable":true,"type":"long"},{"metadata":{},"name":"vehicleSpeed","nullable":true,"type":"double"},{"metadata":{},"name":"id","nullable":true,"type":"string"},{"metadata":{},"name":"patternLine","nullable":true,"type":"string"},{"metadata":{},"name":"directionLine","nullable":true,"type":"string"},{"metadata":{},"name":"delay_interval","nullable":true,"type":"integer"},{"metadata":{},"name":"coordinates","nullable":true,"type":{"containsNull":true,"elementType":"double","type":"array"}},{"metadata":{},"name":"datetime","nullable":true,"type":"string"},{"metadata":{},"name":"dayOfWeek","nullable":true,"type":"integer"},{"metadata":{},"name":"minute","nullable":true,"type":"integer"},{"metadata":{},"name":"hour","nullable":true,"type":"integer"},{"metadata":{},"name":"day","nullable":true,"type":"integer"},{"metadata":{},"name":"month","nullable":true,"type":"integer"},{"metadata":{},"name":"year","nullable":true,"type":"integer"},{"metadata":{},"name":"event_around","nullable":true,"type":"string"},{"metadata":{},"name":"relevant_tweet","nullable":true,"type":"string"},{"metadata":{},"name":"event_around_bool","nullable":false,"type":"boolean"},{"metadata":{},"name":"relevant_tweet_bool","nullable":false,"type":"boolean"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">train len = 212507\ntest len = 23846\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">train len = 212507\ntest len = 23846\n</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"Cancelled","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["preds"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"67b7c20b-08c3-4272-91e2-c2eda2497639"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[88]: DataFrame[actualDelay: double, areaId: bigint, areaId1: bigint, areaId2: bigint, areaId3: bigint, atStop: boolean, busStop: bigint, congestion: boolean, delay: bigint, distanceCovered: double, ellapsedTime: bigint, gridID: string, journeyPatternId: string, justLeftStop: boolean, justStopped: boolean, latitude: double, lineId: string, longitude: double, vehicleId: bigint, vehicleSpeed: double, id: string, patternLine: string, directionLine: string, delay_interval: int, coordinates: array&lt;double&gt;, datetime: string, dayOfWeek: int, minute: int, hour: int, day: int, month: int, year: int, event_around: string, relevant_tweet: string, event_around_bool: boolean, relevant_tweet_bool: boolean, actualDelay_mean: double, patternLine_ix: double, hour_ohe: vector, busStop_ohe: vector, dayOfWeek_ohe: vector, patternLine_ix_ohe: vector, features: vector, delay_interval_rawpred: vector, probability: vector, delay_interval_pred: double]</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[88]: DataFrame[actualDelay: double, areaId: bigint, areaId1: bigint, areaId2: bigint, areaId3: bigint, atStop: boolean, busStop: bigint, congestion: boolean, delay: bigint, distanceCovered: double, ellapsedTime: bigint, gridID: string, journeyPatternId: string, justLeftStop: boolean, justStopped: boolean, latitude: double, lineId: string, longitude: double, vehicleId: bigint, vehicleSpeed: double, id: string, patternLine: string, directionLine: string, delay_interval: int, coordinates: array&lt;double&gt;, datetime: string, dayOfWeek: int, minute: int, hour: int, day: int, month: int, year: int, event_around: string, relevant_tweet: string, event_around_bool: boolean, relevant_tweet_bool: boolean, actualDelay_mean: double, patternLine_ix: double, hour_ohe: vector, busStop_ohe: vector, dayOfWeek_ohe: vector, patternLine_ix_ohe: vector, features: vector, delay_interval_rawpred: vector, probability: vector, delay_interval_pred: double]</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%sh pip install espandas"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"aa140a69-d2c9-4f4d-ad18-187c830e05ef"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["import pickle\nimport pyspark.sql.functions as F\n \nkafka_server = '10.0.0.30:9091'\n \n# Subscribe to a pattern\n# specify the address of kafka\n# specify the pattern of desired topics\n# specify the order of the data (earliest = chronological order)\n\n\n#   .option(\"subscribe\", \"vehicleId_28051,vehicleId_28052\") \\\n#   .option(\"subscribePattern\", \"vehicleId_.*\") \\\n\nkafka_raw_df = spark \\\n  .readStream \\\n  .format(\"kafka\") \\\n  .option(\"kafka.bootstrap.servers\", kafka_server) \\\n  .option(\"subscribePattern\", \"vehicleId_.*\") \\\n  .option(\"startingOffsets\", \"earliest\") \\\n  .option(\"maxOffsetsPerTrigger\", 1000) \\\n  .load()\n\n\nkafka_value_df = kafka_raw_df.selectExpr(\"CAST(value AS STRING)\")\n \nkafka_df = kafka_value_df \\\n           .select(F.from_json(F.col(\"value\"), schema=schema).alias('json')) \\\n           .select(\"json.*\")\n\ndf_es = pd.DataFrame()\nl = []\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"06bccdca-d199-4dd9-af8e-45c4bcb68991"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"kafka_raw_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"key","nullable":true,"type":"binary"},{"metadata":{},"name":"value","nullable":true,"type":"binary"},{"metadata":{},"name":"topic","nullable":true,"type":"string"},{"metadata":{},"name":"partition","nullable":true,"type":"integer"},{"metadata":{},"name":"offset","nullable":true,"type":"long"},{"metadata":{},"name":"timestamp","nullable":true,"type":"timestamp"},{"metadata":{},"name":"timestampType","nullable":true,"type":"integer"}],"type":"struct"},"tableIdentifier":null},{"name":"kafka_value_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"value","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null},{"name":"kafka_df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"_id","nullable":true,"type":{"fields":[{"metadata":{},"name":"$oid","nullable":true,"type":"string"}],"type":"struct"}},{"metadata":{},"name":"actualDelay","nullable":true,"type":"double"},{"metadata":{},"name":"angle","nullable":true,"type":"double"},{"metadata":{},"name":"anomaly","nullable":true,"type":"boolean"},{"metadata":{},"name":"areaId","nullable":true,"type":"long"},{"metadata":{},"name":"areaId1","nullable":true,"type":"long"},{"metadata":{},"name":"areaId2","nullable":true,"type":"long"},{"metadata":{},"name":"areaId3","nullable":true,"type":"long"},{"metadata":{},"name":"atStop","nullable":true,"type":"boolean"},{"metadata":{},"name":"busStop","nullable":true,"type":"long"},{"metadata":{},"name":"calendar","nullable":true,"type":{"fields":[{"metadata":{},"name":"$numberLong","nullable":true,"type":"string"}],"type":"struct"}},{"metadata":{},"name":"congestion","nullable":true,"type":"boolean"},{"metadata":{},"name":"currentHour","nullable":true,"type":"long"},{"metadata":{},"name":"dateType","nullable":true,"type":"long"},{"metadata":{},"name":"dateTypeEnum","nullable":true,"type":"string"},{"metadata":{},"name":"delay","nullable":true,"type":"long"},{"metadata":{},"name":"direction","nullable":true,"type":"long"},{"metadata":{},"name":"distanceCovered","nullable":true,"type":"double"},{"metadata":{},"name":"ellapsedTime","nullable":true,"type":"long"},{"metadata":{},"name":"filteredActualDelay","nullable":true,"type":"long"},{"metadata":{},"name":"gridID","nullable":true,"type":"string"},{"metadata":{},"name":"journeyPatternId","nullable":true,"type":"string"},{"metadata":{},"name":"justLeftStop","nullable":true,"type":"boolean"},{"metadata":{},"name":"justStopped","nullable":true,"type":"boolean"},{"metadata":{},"name":"latitude","nullable":true,"type":"double"},{"metadata":{},"name":"lineId","nullable":true,"type":"string"},{"metadata":{},"name":"loc","nullable":true,"type":{"fields":[{"metadata":{},"name":"coordinates","nullable":true,"type":{"containsNull":true,"elementType":"double","type":"array"}},{"metadata":{},"name":"type","nullable":true,"type":"string"}],"type":"struct"}},{"metadata":{},"name":"longitude","nullable":true,"type":"double"},{"metadata":{},"name":"poiId","nullable":true,"type":"long"},{"metadata":{},"name":"poiId2","nullable":true,"type":"long"},{"metadata":{},"name":"probability","nullable":true,"type":"double"},{"metadata":{},"name":"systemTimestamp","nullable":true,"type":"double"},{"metadata":{},"name":"timestamp","nullable":true,"type":{"fields":[{"metadata":{},"name":"$numberLong","nullable":true,"type":"string"}],"type":"struct"}},{"metadata":{},"name":"vehicleId","nullable":true,"type":"long"},{"metadata":{},"name":"vehicleSpeed","nullable":true,"type":"double"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["from elasticsearch import Elasticsearch\nfrom espandas import Espandas\nimport pandas as pd\nimport datetime\n\nes = Elasticsearch([{'host': ip,}])\nesp = Espandas(hosts=[{'host': ip,}])\n\n\n\nquery_template = '''\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"match_phrase\": {\n            \"patternLine\": \"%%patternLine%%\"\n          }\n        },\n        {\n          \"match_phrase\": {\n            \"directionLine\": \"%%directionLine%%\"\n          }\n        },\n        {\n          \"geo_distance\": {\n            \"distance\": \"200m\",\n            \"coordinates\": [ %%lon%%, %%lat%% ]\n          }\n        },\n        {\n          \"range\": {\n            \"datetime\": {\n              \"gte\": \"2016-01-01T13:00:00.000Z\",\n              \"lte\": \"2019-01-01T14:00:00.000Z\",\n              \"format\": \"strict_date_optional_time\"\n            }\n          }\n        }\n      ]\n    }\n  },\n  \"size\": 0,\n  \"aggs\": {\n    \"longitude_stats\" : { \n      \"extended_stats\" : { \n        \"field\" : \"longitude\" \n      } \n    },\n    \"latitude_stats\" : { \n      \"extended_stats\" : { \n        \"field\" : \"latitude\" \n      } \n    }\n  }  \n}'''\n\n# @F.udf()\n\n\ndef is_anomaly(directionLine, patternLine, lon, lat):\n  q = query_template.replace('%%directionLine%%', str(directionLine)).replace('%%patternLine%%', patternLine).replace('%%lon%%', str(lon)).replace('%%lat%%', str(lat))\n  \n#   l2.append(('start', datetime.datetime.now(), directionLine, patternLine, lon, lat))\n  res = es.search(index=\"df_full\", body=q, request_timeout=30000)\n#   l2.append(('finis', datetime.datetime.now(), directionLine, patternLine, lon, lat))\n  \n  count = res['aggregations']['longitude_stats']['count']\n  if count < 50:\n    return True\n\n  lon_avg = res['aggregations']['longitude_stats']['avg']\n  lon_std = res['aggregations']['longitude_stats']['std_deviation']\n  b1 = (abs(lon - lon_avg) > lon_std)\n\n  lat_avg = res['aggregations']['latitude_stats']['avg']\n  lat_std = res['aggregations']['latitude_stats']['std_deviation']\n  b2 = (abs(lat - lat_avg) > lat_std)\n  return b1 and b2\n\ndef foreach_batch_function(df_stream, batch_id):\n    # Transform and write batchDF\n#     l1.append((batch_id, '1', df_stream.count()))\n    \n    df_stream = pre_process(df_stream)\n    df_stream = remove_outliers(df_stream)\n    df_stream = pipeline_model.transform(df_stream)\n    \n#     l1.append((batch_id, '2'))\n\n# todo: before date\n    unique_cols = ['year', 'month', 'day', 'patternLine', 'directionLine', 'vehicleId']\n    df_pd = df_stream.toPandas()\n    df_pd['anomaly'] = df_pd.apply(lambda r: is_anomaly(r['directionLine'], r['patternLine'], r['longitude'], r['latitude']), axis=1)\n    df_pd['anomaly_trip'] = df_pd.groupby(unique_cols)['anomaly'].transform(sum)>=2\n\n#     l1.append((batch_id, '3'))\n\n    # todo: add tweet and event\n    \n    l.append(df_pd[df_pd['anomaly_trip']][unique_cols+['relevant_tweet', 'event_around', 'delay_interval', 'delay_interval_pred']])\n    df_anomaly = pd.concat(l)\n    \n#     df_anomaly = df_anomaly.drop_duplicates(unique_cols)\n    \n    def get_stats(x):\n      return pd.Series({'prediction_rmse': mean_squared_error(x['delay_interval'], x['delay_interval_pred']),\n                        'prediction_acc': accuracy_score(x['delay_interval'], x['delay_interval_pred']),\n                        'relevant_tweets': list(set(x['relevant_tweet'][x['relevant_tweet']!='no'])),\n                        'events_around': list(set(x['event_around'][x['event_around']!='no']))})\n\n    df_anomaly = df_anomaly[unique_cols+['relevant_tweet', 'event_around', 'delay_interval', 'delay_interval_pred']].groupby(unique_cols).apply(get_stats).reset_index()\n    df_anomaly['anomaly_id'] = range(len(df_anomaly))\n\n#     l1.append((batch_id, '4', len(df_anomaly)))\n    \n    if es.indices.exists('menu_df'):\n      es.indices.delete(index='menu_df')\n    esp.es_write(df_anomaly, 'menu_df', 'doc', uid_name='anomaly_id')\n\n#     l1.append((batch_id, '5'))\n\n# l = []\n# l1 = []\n# l2 = []\ndf_es = pd.DataFrame()\n\nkafka_df.writeStream.foreachBatch(foreach_batch_function).start()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77c5220c-9809-4fc4-b42c-73606bfebef9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[215]: &lt;pyspark.sql.streaming.StreamingQuery at 0x7f3f9e4c9be0&gt;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[215]: &lt;pyspark.sql.streaming.StreamingQuery at 0x7f3f9e4c9be0&gt;</div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"project","dashboards":[],"language":"python","widgets":{"IP (for new stream data)":{"nuid":"cd76b7a5-3145-4979-86f8-8925221d59a4","currentValue":"10.0.0.30","widgetInfo":{"widgetType":"text","name":"IP (for new stream data)","defaultValue":"10.0.0.30","label":null,"options":{"widgetType":"text","validationRegex":null}}},"Path (for new batch data)":{"nuid":"1b5c093d-91b5-4090-b03f-0c98459f55fc","currentValue":"/mnt/dacoursedatabricksstg/dacoursedatabricksdata/busFile","widgetInfo":{"widgetType":"text","name":"Path (for new batch data)","defaultValue":"/mnt/dacoursedatabricksstg/dacoursedatabricksdata/busFile","label":null,"options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":2126588963430369}},"nbformat":4,"nbformat_minor":0}
